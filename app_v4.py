# -*- coding: utf-8 -*-

# =========================================================================================
#  Analisador de Notas Fiscais com CrewAI, Groq e Streamlit
#
#  Autor: Arquiteto de Solu√ß√µes AI
#  Data: 2024-05-21 (Vers√£o Refatorada e Corrigida)
#
#  Descri√ß√£o:
#  Este script implementa uma solu√ß√£o completa para analisar dados de notas fiscais
#  contidas em arquivos CSV. A aplica√ß√£o utiliza uma interface Streamlit para o upload
#  de um arquivo .zip e para a intera√ß√£o com o usu√°rio via chat.
#
#  A l√≥gica de an√°lise √© orquestrada pelo CrewAI, que gerencia dois agentes aut√¥nomos:
#  1.  QueryInterpreterAgent: Converte perguntas em linguagem natural para c√≥digo Python (Pandas).
#  2.  DataAnalysisAndVizAgent: Executa o c√≥digo gerado, analisa os resultados e prepara
#      uma resposta completa com texto, tabelas e gr√°ficos.
#
#  O motor de LLM utilizado √© o Groq, escolhido por sua alta velocidade de infer√™ncia,
#  proporcionando uma experi√™ncia de usu√°rio fluida e em tempo real.
#
#  Como executar:
#  1. Crie um arquivo .env na raiz do projeto com sua GROQ_API_KEY.
#  2. Crie um requirements.txt e instale as depend√™ncias: pip install -r requirements.txt
#  3. Execute o comando no terminal: streamlit run app.py
# =========================================================================================

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import os
import zipfile
import io
import traceback
from textwrap import dedent
import re
import json

# --- Bibliotecas de IA e Agentes ---
from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool
# from langchain_groq import ChatGroq
# from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.chat_models.litellm import ChatLiteLLM
from dotenv import load_dotenv

# --- Carregar vari√°veis de ambiente (GROQ_API_KEY) ---
# Garanta que o arquivo .env est√° na mesma pasta que o app.py
load_dotenv()

# --- Configura√ß√£o do LLM (A ABORDAGEM CORRETA E DEFINITIVA) ---
# Usamos o ChatLiteLLM, a integra√ß√£o direta da LangChain com o LiteLLM.
# Isso garante que o nome do modelo √© passado sem modifica√ß√µes para a camada
# do LiteLLM, resolvendo o conflito de prefixos.
# O LiteLLM ir√° automaticamente pegar a GOOGLE_API_KEY do ambiente.
llm = ChatLiteLLM(
    model="gemini/gemini-1.5-flash-latest",
    api_key=os.environ.get("GOOGLE_API_KEY"),
    temperature=0.0
)

# =========================================================================================
#  FERRAMENTA CUSTOMIZADA (CUSTOM TOOL) PARA OS AGENTES
# =========================================================================================

class PythonCodeExecutorTool(BaseTool):
    """
    Uma ferramenta para executar c√≥digo Python e retornar os resultados.
    Esta ferramenta √© a mais robusta, recebendo o DataFrame em sua inicializa√ß√£o
    para evitar problemas de valida√ß√£o com o Pydantic.
    """
    name: str = "Python Code Executor"
    description: str = dedent("""
        Executa um bloco de c√≥digo Python para an√°lise de dados com Pandas.
        O c√≥digo DEVE operar sobre um DataFrame que j√° est√° dispon√≠vel na ferramenta.
        O script deve:
        1.  Imprimir um resumo textual da an√°lise usando a fun√ß√£o print().
        2.  Atribuir o DataFrame resultante final a uma vari√°vel chamada 'result_df'.
        3.  Gerar um gr√°fico Plotly e atribu√≠-lo a uma vari√°vel chamada 'fig'.
            Se um gr√°fico n√£o for aplic√°vel, 'fig' deve ser None.
    """)
    df: pd.DataFrame = None

    def _run(self, code: str) -> dict:
        """
        Executa o c√≥digo em um ambiente controlado e captura os resultados.
        O DataFrame 'self.df' √© usado na execu√ß√£o.
        """
        if self.df is None:
            return {"error": "DataFrame n√£o foi fornecido para a ferramenta."}

        local_namespace = {'df': self.df, 'pd': pd, 'px': px, 'result_df': None, 'fig': None}
        
        output_capture = io.StringIO()
        import sys
        original_stdout = sys.stdout
        sys.stdout = output_capture
        
        try:
            exec(code, {}, local_namespace)
            
            text_output = output_capture.getvalue()
            result_df = local_namespace.get('result_df')
            fig = local_namespace.get('fig')

            table_output = result_df.to_dict('records') if isinstance(result_df, pd.DataFrame) else None

            return {
                "text_output": text_output,
                "table": table_output,
                "figure": fig
            }
        except Exception as e:
            error_message = f"Erro ao executar o c√≥digo: {e}\nTraceback:\n{traceback.format_exc()}"
            return {"error": error_message, "text_output": error_message}
        finally:
            sys.stdout = original_stdout

# =========================================================================================
#  DEFINI√á√ÉO DOS AGENTES
# =========================================================================================

# Agentes s√£o definidos no escopo global para serem reutilizados.
# Suas configura√ß√µes s√£o est√°veis e n√£o precisam ser recriadas a cada pergunta.

interpreter_agent = Agent(
    role="Tradutor de Linguagem Natural para C√≥digo Python",
    goal="Converter perguntas de usu√°rios em c√≥digo Python (Pandas) execut√°vel e preciso para an√°lise de dados.",
    backstory=dedent("""
        Voc√™ √© um especialista em an√°lise de dados que traduz requisi√ß√µes de neg√≥cio em linguagem natural
        para scripts Python precisos e eficientes usando a biblioteca Pandas. Voc√™ recebe uma pergunta
        e o schema do DataFrame e devolve apenas o c√≥digo necess√°rio para responder √†quela pergunta.
    """),
    llm=llm,
    verbose=True,
    allow_delegation=False
)

analysis_agent = Agent(
    role="Analista de Dados S√™nior e Especialista em Visualiza√ß√£o",
    goal="Executar c√≥digo Python de an√°lise, interpretar os resultados e comunic√°-los de forma clara.",
    backstory=dedent("""
        Voc√™ √© um analista de dados experiente. Sua fun√ß√£o √© pegar um script Python,
        execut√°-lo de forma segura e interpretar os resultados. Voc√™ n√£o escreve
        o c√≥digo, apenas o executa e apresenta as conclus√µes,
        juntamente com tabelas e gr√°ficos relevantes.
    """),
    llm=llm,
    verbose=True,
    allow_delegation=False
)

# =========================================================================================
#  FUN√á√ïES AUXILIARES PARA A INTERFACE STREAMLIT
# =========================================================================================

@st.cache_data
def create_dummy_zip():
    """Cria um arquivo .zip de exemplo em mem√≥ria para demonstra√ß√£o."""
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
        notas_data = {
            'numero_nota': [1001, 1002, 1003, 1004, 1005],
            'data_emissao': ['2024-01-10 09:30:00', '2024-01-15 14:00:00', '2024-01-18 11:00:00', '2024-01-20 16:45:00', '2024-02-05 10:00:00'],
            'fornecedor': ['Fornecedor A', 'Fornecedor B', 'Fornecedor A', 'Fornecedor C', 'Fornecedor B'],
            'valor_total': [1500.50, 850.00, 320.75, 5000.00, 1200.00]
        }
        zf.writestr('notas_fiscais.csv', pd.DataFrame(notas_data).to_csv(index=False))
        itens_data = {
            'numero_nota': [1001, 1001, 1002, 1003, 1004, 1004, 1005],
            'descricao_item': ['Laptop', 'Mouse', 'Teclado', 'Cabo HDMI', 'Servi√ßo de Consultoria', 'Software Licen√ßa', 'Monitor'],
            'quantidade': [5, 10, 10, 15, 1, 1, 8],
            'valor_unitario': [250.00, 25.05, 85.00, 21.3833, 5000.00, 1.00, 150.00]
        }
        zf.writestr('itens_nota.csv', pd.DataFrame(itens_data).to_csv(index=False))
    zip_buffer.seek(0)
    return zip_buffer.getvalue()

def process_zip_file(uploaded_file):
    """
    Descompacta o .zip, l√™ os CSVs, mapeia os nomes de colunas do TCU para nomes padr√£o,
    e os combina usando uma chave composta.
    """
    try:
        # Assumindo que o primeiro arquivo √© o de notas e o segundo o de itens
        # Idealmente, os nomes dos arquivos seriam fixos como 'notas.csv' e 'itens.csv'
        # Por enquanto, vamos manter a premissa de 'notas_fiscais.csv' e 'itens_nota.csv'
        zip_file_name = "xxxxxxxxxx.zip" # Substitua pelo nome real se quiser
        notas_csv_name = 'notas_fiscais.csv' # Nome esperado dentro do zip
        itens_csv_name = 'itens_nota.csv' # Nome esperado dentro do zip

        with zipfile.ZipFile(uploaded_file) as z:
            if notas_csv_name not in z.namelist() or itens_csv_name not in z.namelist():
                st.error(f"O arquivo .zip deve conter '{notas_csv_name}' e '{itens_csv_name}'.")
                st.info(f"Arquivos encontrados no zip: {z.namelist()}")
                return None

            with z.open(notas_csv_name) as nf_file:
                df_notas = pd.read_csv(nf_file)
                st.info(f"Colunas originais em '{notas_csv_name}':")
                st.write(df_notas.columns.tolist())

            with z.open(itens_csv_name) as in_file:
                df_itens = pd.read_csv(in_file)
                st.info(f"Colunas originais em '{itens_csv_name}':")
                st.write(df_itens.columns.tolist())

            # --- MAPEAMENTO DE COLUNAS PARA PADR√ÉO INTERNO ---
            # Mapeia os nomes reais (em min√∫sculas) para os nomes que os agentes v√£o usar.
            notas_mapping = {
                'chave_acesso': ['chave de acesso'],
                'modelo': ['modelo'],
                'serie': ['s√©rie'],
                'numero_nota': ['n√∫mero'],
                'natureza_operacao': ['natureza da opera√ß√£o'],
                'data_emissao': ['data emiss√£o'],
                'fornecedor': ['raz√£o social emitente'], # Usando o emitente como fornecedor
                'valor_total': ['valor nota fiscal']
            }

            itens_mapping = {
                'chave_acesso': ['chave de acesso'],
                'modelo': ['modelo'],
                'serie': ['s√©rie'],
                'numero_nota': ['n√∫mero'],
                'descricao_item': ['descri√ß√£o do produto/servi√ßo'],
                'quantidade': ['quantidade'],
                'valor_unitario': ['valor unit√°rio']
                # O 'valor total' do item ser√° calculado, ent√£o n√£o precisamos mapear
            }

            def rename_columns(df, mapping):
                renamed_cols = {}
                df_cols_lower = {col.lower(): col for col in df.columns}
                for standard_name, possible_names in mapping.items():
                    for p_name in possible_names:
                        if p_name in df_cols_lower:
                            renamed_cols[df_cols_lower[p_name]] = standard_name
                            break
                df.rename(columns=renamed_cols, inplace=True)
                return df

            df_notas = rename_columns(df_notas, notas_mapping)
            df_itens = rename_columns(df_itens, itens_mapping)
            
            # --- CHAVE DE MERGE COMPOSTA ---
            # As colunas que identificam unicamente uma nota fiscal
            merge_keys = ['chave_acesso', 'modelo', 'serie', 'numero_nota']

            # Seleciona apenas as colunas que vamos usar para evitar redund√¢ncia
            cols_to_keep_notas = merge_keys + ['data_emissao', 'fornecedor', 'valor_total']
            df_notas_final = df_notas[[col for col in cols_to_keep_notas if col in df_notas.columns]]

            cols_to_keep_itens = merge_keys + ['descricao_item', 'quantidade', 'valor_unitario']
            df_itens_final = df_itens[[col for col in cols_to_keep_itens if col in df_itens.columns]]

            # Valida√ß√£o
            if not all(key in df_notas_final.columns for key in merge_keys) or \
               not all(key in df_itens_final.columns for key in merge_keys):
                st.error("As colunas da chave de merge n√£o foram encontradas em ambos os arquivos ap√≥s o mapeamento.")
                st.write("Chaves esperadas:", merge_keys)
                st.write("Colunas encontradas em Notas:", df_notas_final.columns.tolist())
                st.write("Colunas encontradas em Itens:", df_itens_final.columns.tolist())
                return None

            st.success("Colunas mapeadas e prontas para o merge:")
            st.write("Notas:", df_notas_final.columns.tolist())
            st.write("Itens:", df_itens_final.columns.tolist())

            # Convers√£o de tipos de dados antes do merge
            df_notas_final['data_emissao'] = pd.to_datetime(df_notas_final['data_emissao'], errors='coerce')
            
            # Converte colunas num√©ricas, tratando v√≠rgulas como separador decimal
            for col in ['valor_total']:
                 if col in df_notas_final.columns:
                    df_notas_final[col] = df_notas_final[col].astype(str).str.replace(',', '.').astype(float)
            
            for col in ['quantidade', 'valor_unitario']:
                 if col in df_itens_final.columns:
                    df_itens_final[col] = df_itens_final[col].astype(str).str.replace(',', '.').astype(float)

            # --- MERGE FINAL USANDO A CHAVE COMPOSTA ---
            df_merged = pd.merge(df_notas_final, df_itens_final, on=merge_keys, how='inner')
            st.success("Merge dos arquivos realizado com sucesso usando a chave composta!")
            
            return df_merged
            
    except Exception as e:
        st.error(f"Ocorreu um erro cr√≠tico ao processar o arquivo .zip: {e}")
        traceback.print_exc()
        return None

def extract_result_from_output(output):
    """
    Extrai o resultado da execu√ß√£o do agente, tratando diferentes formatos de sa√≠da.
    """
    try:
        # Se o output j√° √© um dicion√°rio, usa diretamente
        if isinstance(output, dict):
            return output
        
        # Se √© uma string, tenta fazer parse como JSON
        if isinstance(output, str):
            # Tenta encontrar um JSON v√°lido na string
            try:
                return json.loads(output)
            except json.JSONDecodeError:
                # Se n√£o conseguir fazer parse do JSON, procura por padr√µes
                # Isso √© um fallback para casos onde a string cont√©m o resultado mas n√£o √© JSON puro
                return {"text_output": output, "table": None, "figure": None}
        
        # Se tem atributo raw, usa ele
        if hasattr(output, 'raw'):
            return extract_result_from_output(output.raw)
        
        # Se tem atributo result, usa ele
        if hasattr(output, 'result'):
            return extract_result_from_output(output.result)
        
        # Fallback: converte para string
        return {"text_output": str(output), "table": None, "figure": None}
        
    except Exception as e:
        return {"error": f"Erro ao processar resultado: {str(e)}"}

def convert_plotly_dict_to_figure(fig_dict):
    """
    Converte um dicion√°rio Plotly em um objeto Figure v√°lido.
    """
    try:
        if fig_dict is None:
            return None
        
        if isinstance(fig_dict, dict):
            # Importa plotly.graph_objects para criar a figura
            import plotly.graph_objects as go
            
            # Cria a figura a partir do dicion√°rio
            fig = go.Figure(fig_dict)
            return fig
        else:
            # Se j√° √© um objeto Figure, retorna como est√°
            return fig_dict
            
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel converter o gr√°fico: {e}")
        return None

def clean_ansi_codes(text):
    """Fun√ß√£o para remover c√≥digos de cor ANSI do texto."""
    if not isinstance(text, str):
        return str(text)
    ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
    return ansi_escape.sub('', text)

# =========================================================================================
#  INTERFACE DO USU√ÅRIO (STREAMLIT)
# =========================================================================================

st.set_page_config(page_title="Analisador de Notas Fiscais com CrewAI", layout="wide")
st.title("ü§ñ Analisador de Notas Fiscais com Agentes Aut√¥nomos")
st.markdown("Fa√ßa perguntas em linguagem natural sobre seus dados de notas fiscais.")

if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'df_analysis' not in st.session_state:
    st.session_state.df_analysis = None
if 'df_schema' not in st.session_state:
    st.session_state.df_schema = None

with st.sidebar:
    st.header("1. Carregue seus dados")
    uploaded_file = st.file_uploader("Selecione o arquivo .zip", type="zip")
    if st.button("Usar Dados de Exemplo"):
        uploaded_file = io.BytesIO(create_dummy_zip())
        st.success("Dados de exemplo carregados!")

    if uploaded_file is not None and st.session_state.df_analysis is None:
        with st.spinner("Processando e combinando arquivos..."):
            df = process_zip_file(uploaded_file)
            if df is not None:
                st.session_state.df_analysis = df
                schema_buffer = io.StringIO()
                df.info(buf=schema_buffer)
                st.session_state.df_schema = schema_buffer.getvalue()
                st.success("Arquivos processados com sucesso!")

    if st.session_state.df_analysis is not None:
        st.header("Dados Carregados")
        st.dataframe(st.session_state.df_analysis.head())
        st.info(f"{len(st.session_state.df_analysis)} linhas de dados combinados.")

if st.session_state.df_analysis is None:
    st.info("Por favor, carregue um arquivo .zip ou use os dados de exemplo para come√ßar.")
else:
    # Exibir hist√≥rico de mensagens
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant":
                # Formata√ß√£o especial para respostas do assistente
                if message["content"] and message["content"].strip():
                    st.markdown(f"**üìä Resultado da An√°lise:**")
                    st.markdown(message["content"])
                
                if "table" in message and message["table"] is not None:
                    try:
                        df_table = pd.DataFrame(message["table"])
                        if not df_table.empty:
                            st.markdown("**üìã Detalhamento dos Dados:**")
                            st.dataframe(df_table, use_container_width=True)
                    except:
                        pass
                
                if "figure" in message and message["figure"] is not None:
                    try:
                        st.markdown("**üìà Visualiza√ß√£o:**")
                        st.plotly_chart(message["figure"], use_container_width=True)
                    except:
                        pass
            else:
                # Mensagens do usu√°rio
                st.markdown(message["content"])

    # Campo de entrada para nova pergunta
    if prompt := st.chat_input("Qual sua pergunta? Ex: Qual o item mais vendido?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Analisando sua pergunta com a equipe de agentes..."):
                try:
                    # 1. Instanciar a ferramenta com o DataFrame da sess√£o ATUAL
                    code_executor_tool = PythonCodeExecutorTool(df=st.session_state.df_analysis)

                    # 2. Criar as tarefas para a execu√ß√£o ATUAL
                    task_interpret = Task(
                        description=dedent(f"""
                            Sua tarefa √© escrever um script Python para responder √† pergunta de um usu√°rio sobre dados de notas fiscais.

                            **REGRAS ABSOLUTAS:**
                            1.  Voc√™ deve usar um DataFrame que j√° existe na mem√≥ria, chamado `df`.
                            2.  **N√ÉO** inclua `pd.read_csv()` ou qualquer outra fun√ß√£o de leitura de arquivo no seu c√≥digo.
                            3.  Seu script DEVE produzir as seguintes vari√°veis como resultado:
                                - `result_df`: um DataFrame pandas com os dados da resposta.
                                - `fig`: uma figura do Plotly Express (use `px.bar`, `px.pie`, etc.). Se nenhum gr√°fico for aplic√°vel, use `fig = None`.
                                - Use `print()` para escrever um resumo textual da sua descoberta.
                            4.  O seu output final deve ser **APENAS O C√ìDIGO PYTHON**. N√£o inclua a palavra "python" no in√≠cio, nem ` ``` `, nem qualquer explica√ß√£o.

                            **SCHEMA DO DATAFRAME `df` DISPON√çVEL:**
                            ```
                            {st.session_state.df_schema}
                            ```

                            **PERGUNTA DO USU√ÅRIO:**
                            "{prompt}"

                            Agora, escreva o c√≥digo Python completo e v√°lido para responder a esta pergunta.
                        """),
                        agent=interpreter_agent,
                        expected_output="Um bloco de c√≥digo Python puro, completo e sintaticamente correto."
                    )

                    task_execute = Task(
                        description="Use a ferramenta 'Python Code Executor' para executar o script Python da tarefa anterior.",
                        agent=analysis_agent,
                        context=[task_interpret],
                        tools=[code_executor_tool],
                        expected_output="Um dicion√°rio Python com as chaves 'text_output', 'table' e 'figure'."
                    )

                    # 3. Criar e executar a Crew
                    analysis_crew = Crew(
                        agents=[interpreter_agent, analysis_agent],
                        tasks=[task_interpret, task_execute],
                        process=Process.sequential,
                        verbose=True
                    )
                    
                    # A execu√ß√£o popula o atributo 'output' das tarefas
                    crew_result = analysis_crew.kickoff()

                    # 4. Tratamento e exibi√ß√£o do resultado (VERS√ÉO CORRIGIDA)
                    # Usa a fun√ß√£o helper para extrair o resultado
                    final_output = extract_result_from_output(task_execute.output)
                    
                    # Verifica se h√° erro expl√≠cito
                    if isinstance(final_output, dict) and "error" in final_output:
                        # H√° um erro expl√≠cito
                        error_msg = final_output["error"]
                        st.error(f"Erro na execu√ß√£o: {error_msg}")
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": f"Desculpe, ocorreu um erro: {error_msg}"
                        })
                    else:
                        # Tenta processar como resultado v√°lido
                        try:
                            # Extrai os componentes do resultado
                            response_text = clean_ansi_codes(final_output.get('text_output', "An√°lise conclu√≠da."))
                            response_table = final_output.get('table')
                            response_figure_dict = final_output.get('figure')
                            
                            # Converte o dicion√°rio do gr√°fico em um objeto Figure
                            response_figure = convert_plotly_dict_to_figure(response_figure_dict)

                            # Exibe o texto de forma mais elegante
                            if response_text and response_text.strip():
                                # Remove linhas vazias e formata melhor
                                clean_text = response_text.strip()
                                if clean_text:
                                    st.markdown(f"**üìä Resultado da An√°lise:**")
                                    st.markdown(clean_text)
                            
                            # Exibe a tabela se dispon√≠vel
                            if response_table is not None:
                                try:
                                    df_table = pd.DataFrame(response_table)
                                    if not df_table.empty:
                                        st.markdown("**üìã Detalhamento dos Dados:**")
                                        st.dataframe(df_table, use_container_width=True)
                                except Exception as e:
                                    st.warning(f"N√£o foi poss√≠vel exibir a tabela: {e}")
                            
                            # Exibe o gr√°fico se dispon√≠vel
                            if response_figure is not None:
                                try:
                                    st.markdown("**üìà Visualiza√ß√£o:**")
                                    st.plotly_chart(response_figure, use_container_width=True)
                                except Exception as e:
                                    st.warning(f"N√£o foi poss√≠vel exibir o gr√°fico: {e}")
                                    # Fallback: mostra que h√° um gr√°fico dispon√≠vel
                                    st.info("Um gr√°fico foi gerado mas n√£o p√¥de ser exibido.")
                            
                            # Adiciona ao hist√≥rico - s√≥ o texto limpo para n√£o poluir
                            clean_text_for_history = clean_ansi_codes(final_output.get('text_output', "An√°lise conclu√≠da.")).strip()
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": clean_text_for_history,
                                "table": response_table,
                                "figure": response_figure
                            })
                            
                        except Exception as e:
                            st.error(f"Erro ao processar resultado: {str(e)}")
                            # Debug info apenas quando h√° erro
                            with st.expander("üîç Informa√ß√µes de Debug"):
                                st.write("Tipo do resultado:", type(final_output))
                                st.write("Resultado bruto:", final_output)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": f"Desculpe, ocorreu um erro ao processar o resultado: {str(e)}"
                            })

                except Exception as e:
                    st.error(f"Erro geral na execu√ß√£o: {str(e)}")
                    st.write("Traceback:", traceback.format_exc())
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": f"Desculpe, ocorreu um erro inesperado: {str(e)}"
                    })